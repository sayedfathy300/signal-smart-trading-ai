// Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„ØªÙØ³ÙŠØ±ÙŠ - Explainable AI Service
// ØªØªØ¶Ù…Ù† SHAPØŒ Feature ImportanceØŒ ÙˆØªÙØ³ÙŠØ± Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª

export interface SHAPValue {
  feature: string;
  value: number;
  importance: number;
  contribution: number;
  baseline: number;
}

export interface FeatureImportance {
  feature: string;
  importance: number;
  rank: number;
  category: 'technical' | 'fundamental' | 'sentiment' | 'alternative';
  description: string;
}

export interface DecisionExplanation {
  decision: 'buy' | 'sell' | 'hold';
  confidence: number;
  main_factors: string[];
  supporting_evidence: string[];
  risk_factors: string[];
  alternative_scenarios: {
    scenario: string;
    probability: number;
    outcome: string;
  }[];
}

export interface ModelExplanation {
  model_name: string;
  prediction: number;
  shap_values: SHAPValue[];
  feature_importance: FeatureImportance[];
  decision_explanation: DecisionExplanation;
  counterfactual_analysis: {
    original_prediction: number;
    counterfactual_prediction: number;
    changed_features: string[];
    explanation: string;
  };
  lime_explanation: {
    feature: string;
    weight: number;
    local_importance: number;
  }[];
}

export interface ExplainabilityReport {
  symbol: string;
  timestamp: Date;
  model_explanations: ModelExplanation[];
  global_feature_importance: FeatureImportance[];
  decision_tree_visualization: {
    nodes: Array<{
      id: string;
      condition: string;
      samples: number;
      value: number;
      type: 'decision' | 'leaf';
    }>;
    edges: Array<{
      from: string;
      to: string;
      condition: string;
    }>;
  };
  interpretability_score: number;
  bias_analysis: {
    demographic_parity: number;
    equalized_odds: number;
    calibration: number;
    fairness_score: number;
  };
}

class ExplainableAIService {
  private shapImplementation: any;
  private limeImplementation: any;

  constructor() {
    this.initializeExplainabilityModels();
  }

  private async initializeExplainabilityModels() {
    try {
      console.log('ğŸ” ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙØ³ÙŠØ±...');
      
      // Ù…Ø­Ø§ÙƒØ§Ø© ØªÙ‡ÙŠØ¦Ø© SHAP Ùˆ LIME
      this.shapImplementation = {
        explainer: 'TreeExplainer',
        initialized: true
      };
      
      this.limeImplementation = {
        explainer: 'LimeTabular',
        initialized: true
      };
      
      console.log('âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙØ³ÙŠØ± Ø¨Ù†Ø¬Ø§Ø­');
    } catch (error) {
      console.error('âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªÙØ³ÙŠØ±:', error);
    }
  }

  async generateSHAPValues(
    features: Record<string, number>,
    model: string
  ): Promise<SHAPValue[]> {
    console.log(`ğŸ¯ Ø­Ø³Ø§Ø¨ Ù‚ÙŠÙ… SHAP Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ${model}...`);
    
    const featureNames = Object.keys(features);
    const baseline = 0.5; // Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
    
    return featureNames.map(feature => {
      const value = features[feature];
      const importance = Math.random() * 0.6 + 0.1; // Ø£Ù‡Ù…ÙŠØ© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©
      const contribution = (value - baseline) * importance * (Math.random() > 0.5 ? 1 : -1);
      
      return {
        feature,
        value,
        importance,
        contribution,
        baseline
      };
    }).sort((a, b) => Math.abs(b.contribution) - Math.abs(a.contribution));
  }

  async calculateFeatureImportance(
    features: Record<string, number>,
    model: string
  ): Promise<FeatureImportance[]> {
    console.log(`ğŸ“Š Ø­Ø³Ø§Ø¨ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø®ØµØ§Ø¦Øµ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ${model}...`);
    
    const technicalFeatures = ['RSI', 'MACD', 'MA20', 'MA50', 'Bollinger_Upper', 'Bollinger_Lower'];
    const fundamentalFeatures = ['PE_Ratio', 'EPS', 'Revenue_Growth', 'Debt_Ratio'];
    const sentimentFeatures = ['News_Sentiment', 'Social_Sentiment', 'Fear_Greed_Index'];
    const alternativeFeatures = ['Google_Trends', 'Satellite_Data', 'Credit_Card_Spending'];
    
    const allFeatures = [
      ...technicalFeatures.map(f => ({ name: f, category: 'technical' as const })),
      ...fundamentalFeatures.map(f => ({ name: f, category: 'fundamental' as const })),
      ...sentimentFeatures.map(f => ({ name: f, category: 'sentiment' as const })),
      ...alternativeFeatures.map(f => ({ name: f, category: 'alternative' as const }))
    ];
    
    return allFeatures.map((feature, index) => ({
      feature: feature.name,
      importance: Math.random() * 0.8 + 0.1,
      rank: index + 1,
      category: feature.category,
      description: this.getFeatureDescription(feature.name)
    })).sort((a, b) => b.importance - a.importance);
  }

  private getFeatureDescription(feature: string): string {
    const descriptions: Record<string, string> = {
      'RSI': 'Ù…Ø¤Ø´Ø± Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù†Ø³Ø¨ÙŠØ© - ÙŠÙ‚ÙŠØ³ Ø²Ø®Ù… Ø§Ù„Ø³Ø¹Ø±',
      'MACD': 'Ù…Ø¤Ø´Ø± ØªÙ‚Ø§Ø±Ø¨ ÙˆØªØ¨Ø§Ø¹Ø¯ Ø§Ù„Ù…ØªÙˆØ³Ø·Ø§Øª Ø§Ù„Ù…ØªØ­Ø±ÙƒØ©',
      'MA20': 'Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù„Ù€ 20 ÙŠÙˆÙ…',
      'MA50': 'Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù„Ù€ 50 ÙŠÙˆÙ…',
      'PE_Ratio': 'Ù†Ø³Ø¨Ø© Ø§Ù„Ø³Ø¹Ø± Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø±Ø¨Ø§Ø­',
      'EPS': 'Ø±Ø¨Ø­ÙŠØ© Ø§Ù„Ø³Ù‡Ù… Ø§Ù„ÙˆØ§Ø­Ø¯',
      'News_Sentiment': 'Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø§Ù„ÙŠØ©',
      'Google_Trends': 'Ø§ØªØ¬Ø§Ù‡Ø§Øª Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬ÙˆØ¬Ù„'
    };
    
    return descriptions[feature] || 'ÙˆØµÙ ØºÙŠØ± Ù…ØªÙˆÙØ±';
  }

  async explainDecision(
    prediction: number,
    features: Record<string, number>,
    model: string
  ): Promise<DecisionExplanation> {
    console.log(`ğŸ’¡ ØªÙØ³ÙŠØ± Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ${model}...`);
    
    const decision = prediction > 0.6 ? 'buy' : prediction < 0.4 ? 'sell' : 'hold';
    const confidence = Math.abs(prediction - 0.5) * 2;
    
    const mainFactors = [
      'RSI ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…Ù†Ø·Ù‚Ø© Ø°Ø±ÙˆØ© Ø§Ù„Ø¨ÙŠØ¹',
      'MACD ÙŠØ¸Ù‡Ø± Ø¥Ø´Ø§Ø±Ø© ØµØ¹ÙˆØ¯ÙŠØ© Ù‚ÙˆÙŠØ©',
      'Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ Ø£Ø¹Ù„Ù‰ Ù…Ù† Ø§Ù„Ù…ØªÙˆØ³Ø·'
    ];
    
    const supportingEvidence = [
      'Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©',
      'Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© ØªØ¯Ø¹Ù… Ø§Ù„Ø§ØªØ¬Ø§Ù‡',
      'Ø§Ù„Ø³ÙŠÙˆÙ„Ø© ÙƒØ§ÙÙŠØ© Ù„Ù„Ø¯Ø®ÙˆÙ„'
    ];
    
    const riskFactors = [
      'ØªÙ‚Ù„Ø¨Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù„ÙŠØ©',
      'Ø¹Ø¯Ù… Ø§Ù„ÙŠÙ‚ÙŠÙ† Ø§Ù„Ø§Ù‚ØªØµØ§Ø¯ÙŠ',
      'Ù…Ù‚Ø§ÙˆÙ…Ø© ÙÙ†ÙŠØ© Ù‚Ø±ÙŠØ¨Ø©'
    ];
    
    const alternativeScenarios = [
      {
        scenario: 'ÙƒØ³Ø± Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©',
        probability: 0.3,
        outcome: 'Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„ØµØ¹ÙˆØ¯ Ø¨Ù‚ÙˆØ©'
      },
      {
        scenario: 'Ø§Ø±ØªØ¯Ø§Ø¯ Ù…Ù† Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø©',
        probability: 0.4,
        outcome: 'ØªØµØ­ÙŠØ­ Ù…Ø¤Ù‚Øª'
      },
      {
        scenario: 'Ø¯Ø¹Ù… Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ',
        probability: 0.3,
        outcome: 'Ø­Ø±ÙƒØ© Ø¬Ø§Ù†Ø¨ÙŠØ©'
      }
    ];
    
    return {
      decision,
      confidence,
      main_factors: mainFactors,
      supporting_evidence: supportingEvidence,
      risk_factors: riskFactors,
      alternative_scenarios: alternativeScenarios
    };
  }

  async generateLIMEExplanation(
    features: Record<string, number>,
    model: string
  ): Promise<{ feature: string; weight: number; local_importance: number }[]> {
    console.log(`ğŸ”¬ ØªÙˆÙ„ÙŠØ¯ ØªÙØ³ÙŠØ± LIME Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ${model}...`);
    
    return Object.keys(features).map(feature => ({
      feature,
      weight: (Math.random() - 0.5) * 2,
      local_importance: Math.random()
    })).sort((a, b) => Math.abs(b.weight) - Math.abs(a.weight));
  }

  async generateCounterfactualAnalysis(
    originalFeatures: Record<string, number>,
    model: string
  ): Promise<{
    original_prediction: number;
    counterfactual_prediction: number;
    changed_features: string[];
    explanation: string;
  }> {
    console.log(`ğŸ”„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ${model}...`);
    
    const originalPrediction = Math.random();
    const counterfactualPrediction = Math.random();
    
    const changedFeatures = Object.keys(originalFeatures)
      .slice(0, 3)
      .map(f => f);
    
    const explanation = `Ø¥Ø°Ø§ ØªØºÙŠØ±Øª ${changedFeatures.join(', ')} Ø¨Ù†Ø³Ø¨Ø© 10%ØŒ ÙØ¥Ù† Ø§Ù„ØªÙ†Ø¨Ø¤ Ø³ÙŠØªØºÙŠØ± Ù…Ù† ${(originalPrediction * 100).toFixed(1)}% Ø¥Ù„Ù‰ ${(counterfactualPrediction * 100).toFixed(1)}%`;
    
    return {
      original_prediction: originalPrediction,
      counterfactual_prediction: counterfactualPrediction,
      changed_features: changedFeatures,
      explanation
    };
  }

  async generateDecisionTreeVisualization() {
    console.log('ğŸŒ³ ØªÙˆÙ„ÙŠØ¯ ØªØµÙˆØ± Ø´Ø¬Ø±Ø© Ø§Ù„Ù‚Ø±Ø§Ø±...');
    
    const nodes = [
      { id: '1', condition: 'RSI < 30', samples: 1000, value: 0.8, type: 'decision' as const },
      { id: '2', condition: 'MACD > 0', samples: 600, value: 0.9, type: 'decision' as const },
      { id: '3', condition: 'Buy Signal', samples: 400, value: 0.95, type: 'leaf' as const },
      { id: '4', condition: 'Hold Signal', samples: 200, value: 0.5, type: 'leaf' as const },
      { id: '5', condition: 'Sell Signal', samples: 400, value: 0.1, type: 'leaf' as const }
    ];
    
    const edges = [
      { from: '1', to: '2', condition: 'True' },
      { from: '1', to: '5', condition: 'False' },
      { from: '2', to: '3', condition: 'True' },
      { from: '2', to: '4', condition: 'False' }
    ];
    
    return { nodes, edges };
  }

  async generateBiasAnalysis(): Promise<{
    demographic_parity: number;
    equalized_odds: number;
    calibration: number;
    fairness_score: number;
  }> {
    console.log('âš–ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ­ÙŠØ² ÙˆØ§Ù„Ø¹Ø¯Ø§Ù„Ø©...');
    
    const demographicParity = Math.random() * 0.3 + 0.7;
    const equalizedOdds = Math.random() * 0.3 + 0.7;
    const calibration = Math.random() * 0.3 + 0.7;
    const fairnessScore = (demographicParity + equalizedOdds + calibration) / 3;
    
    return {
      demographic_parity: demographicParity,
      equalized_odds: equalizedOdds,
      calibration,
      fairness_score: fairnessScore
    };
  }

  async generateExplainabilityReport(
    symbol: string,
    features: Record<string, number>
  ): Promise<ExplainabilityReport> {
    console.log(`ğŸ“‹ ØªÙˆÙ„ÙŠØ¯ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ø±Ù…Ø² ${symbol}...`);
    
    const models = ['LSTM', 'Transformer', 'RandomForest', 'GradientBoosting'];
    const modelExplanations: ModelExplanation[] = [];
    
    for (const model of models) {
      const prediction = Math.random();
      const shapValues = await this.generateSHAPValues(features, model);
      const featureImportance = await this.calculateFeatureImportance(features, model);
      const decisionExplanation = await this.explainDecision(prediction, features, model);
      const counterfactualAnalysis = await this.generateCounterfactualAnalysis(features, model);
      const limeExplanation = await this.generateLIMEExplanation(features, model);
      
      modelExplanations.push({
        model_name: model,
        prediction,
        shap_values: shapValues,
        feature_importance: featureImportance,
        decision_explanation: decisionExplanation,
        counterfactual_analysis: counterfactualAnalysis,
        lime_explanation: limeExplanation
      });
    }
    
    const globalFeatureImportance = await this.calculateFeatureImportance(features, 'ensemble');
    const decisionTreeVisualization = await this.generateDecisionTreeVisualization();
    const biasAnalysis = await this.generateBiasAnalysis();
    
    return {
      symbol,
      timestamp: new Date(),
      model_explanations: modelExplanations,
      global_feature_importance: globalFeatureImportance,
      decision_tree_visualization: decisionTreeVisualization,
      interpretability_score: Math.random() * 0.3 + 0.7,
      bias_analysis: biasAnalysis
    };
  }

  async analyzeFeatureInteractions(
    features: Record<string, number>
  ): Promise<{
    interaction: string;
    strength: number;
    description: string;
  }[]> {
    console.log('ğŸ”— ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØ§Ø¹Ù„Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ø®ØµØ§Ø¦Øµ...');
    
    const interactions = [
      {
        interaction: 'RSI Ã— MACD',
        strength: Math.random() * 0.5 + 0.3,
        description: 'ØªÙØ§Ø¹Ù„ Ù‚ÙˆÙŠ Ø¨ÙŠÙ† Ù…Ø¤Ø´Ø±ÙŠ RSI Ùˆ MACD ÙÙŠ ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¯Ø®ÙˆÙ„'
      },
      {
        interaction: 'Volume Ã— Price',
        strength: Math.random() * 0.4 + 0.4,
        description: 'Ø¹Ù„Ø§Ù‚Ø© Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© Ø¨ÙŠÙ† Ø­Ø¬Ù… Ø§Ù„ØªØ¯Ø§ÙˆÙ„ ÙˆØ­Ø±ÙƒØ© Ø§Ù„Ø³Ø¹Ø±'
      },
      {
        interaction: 'News Sentiment Ã— Market Cap',
        strength: Math.random() * 0.3 + 0.2,
        description: 'ØªØ£Ø«ÙŠØ± Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙŠØ®ØªÙ„Ù Ø­Ø³Ø¨ Ø­Ø¬Ù… Ø§Ù„Ø´Ø±ÙƒØ©'
      }
    ];
    
    return interactions.sort((a, b) => b.strength - a.strength);
  }

  async generateExplanationSummary(
    report: ExplainabilityReport
  ): Promise<{
    key_insights: string[];
    model_consensus: string;
    confidence_level: 'high' | 'medium' | 'low';
    actionable_recommendations: string[];
  }> {
    console.log('ğŸ“ ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ù„ØªÙØ³ÙŠØ±...');
    
    const keyInsights = [
      'Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§ØªØ¬Ø§Ù‡ ØµØ¹ÙˆØ¯ÙŠ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¯Ù‰',
      'RSI Ù‡Ùˆ Ø£Ù‡Ù… Ù…Ø¤Ø´Ø± ÙÙ†ÙŠ ÙÙŠ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ',
      'Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ØªØ¯Ø¹Ù… Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©',
      'Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬'
    ];
    
    const modelConsensus = 'Ø§ØªÙØ§Ù‚ 75% Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø¹Ù„Ù‰ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø´Ø±Ø§Ø¡';
    const confidenceLevel = 'high' as const;
    
    const actionableRecommendations = [
      'Ø§Ø¯Ø®Ù„ Ø¨Ø­Ø¬Ù… Ù…Ø±ÙƒØ² Ù…ØªÙˆØ³Ø· Ù…Ø¹ ÙˆÙ‚Ù Ø®Ø³Ø§Ø±Ø© Ø¹Ù†Ø¯ 5%',
      'Ø±Ø§Ù‚Ø¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ù‚Ø±ÙŠØ¨Ø©',
      'ØªØ§Ø¨Ø¹ Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ø±ÙƒØ© ÙˆØ§Ù„Ù‚Ø·Ø§Ø¹',
      'Ø£Ø¹Ø¯ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ÙˆÙ‚Ù Ø®Ù„Ø§Ù„ 3-5 Ø£ÙŠØ§Ù…'
    ];
    
    return {
      key_insights: keyInsights,
      model_consensus: modelConsensus,
      confidence_level: confidenceLevel,
      actionable_recommendations: actionableRecommendations
    };
  }
}

export const explainableAIService = new ExplainableAIService();
